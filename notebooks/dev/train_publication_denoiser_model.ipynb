{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:48:12.773667419Z",
     "start_time": "2023-12-13T16:48:07.730997953Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "from astrocast.denoising import Network, PyTorchNetwork, SubFrameDataset, SubFrameGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa9acaea5ded71",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# General considerations\n",
    "\n",
    "This training is generally a one-time requirement; once completed, the model can be reapplied to subsequent datasets without the need for retraining. The training phase can range from 1 to 12 hours, depending on the complexity of the data and computational resources. The architecture used in astroCAST is modeled on the suggested network published in [Lecoq et. al. 2021](https://doi.org/10.1038/s41592-021-01285-2). \n",
    "\n",
    "### Table 1: Parameters for denoiser training\n",
    "\n",
    "| Parameter               | Default value         | Comment                                                                                                         |\n",
    "|-------------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------|\n",
    "| **Input Data**          |                       |                                                                                                                 |\n",
    "| `training_files`        | `path/to/training/files` | Path to your training files. Accepts individual file paths or multiple files (e.g., `./train_*.h5`).           |\n",
    "| `validation_files`      |                       | Path to your validation files, similar to training files.                                                       |\n",
    "| `loc`                   | `dataset_name`        | Specifies the location inside `.h5` files.                                                                      |\n",
    "| `batch_size` / `batch_size_val` | `32`          | Number of data samples processed at once. Can be reduced if memory is a constraint.                             |\n",
    "| `max_per_file` / `max_per_val_file` | `16`      | Limits the number of training samples per video to avoid overtraining. Aim for one to few minutes per training epoch. |\n",
    "| **Data Transformation** |                       |                                                                                                                 |\n",
    "| `train_rotation`        | `(1, 2, 3)`           | Allows rotating training images to increase data variety. Rotation in steps of 90Â°.                             |\n",
    "| `train_flip`            | `(0, 1)`              | Allows flipping training images, again for variety.                                                             |\n",
    "| `normalize`             | `global`              | Controls scaling of input data. Global normalization is recommended.                                            |\n",
    "| `batch_normalize`       | `False`               | Optional feature to further scale data during training.                                                         |\n",
    "| **Denoiser Architecture** |                     |                                                                                                                 |\n",
    "| `input_size`            | `(256, 256)`          | Size of the area denoised at once. Should ideally match your frame size.                                        |\n",
    "| `n_stacks`              | `2`                   | Layers in the encoder and decoder. More layers might improve quality but also increase complexity.              |\n",
    "| `kernel`                | `32`                  | Complexity of the initial layer. Higher values may improve results but increase risk of overfitting.            |\n",
    "| `pre_post_frames`       | `5`                   | Frames around the target frame used for denoising. More frames might improve quality but increase requirements.  |\n",
    "| `gap_frames`            | `0`                   | Skips frames immediately before and after the target frame for better denoising in some cases.                  |\n",
    "| **Training Parameters** |                       |                                                                                                                 |\n",
    "| `epochs`                | `10`                  | Maximum training cycles. Can be high if using early stopping.                                                   |\n",
    "| `loss`                  | `annealed_loss`       | Loss function used to assess reconstruction quality.                                                           |\n",
    "| `learning_rate`         | `0.001`               | Speed of model learning. Too high values can make the model unstable.                                           |\n",
    "| `decay_rate`, `decay_steps` | `0.99`, `250`     | Gradually reduces the learning rate for stability.                                                              |\n",
    "| `patience`              | `3`                   | Stops training if no improvement after this many cycles.                                                        |\n",
    "| `min_delta`             | `0.001`               | What's considered an \"improvement\" in model performance.                                                        |\n",
    "| `pretrained_weights`    | `None`                | Use weights from a previous model to speed up training or for transfer learning.                                |\n",
    "| `use_cpu`               | `True`                | Use CPU or GPU for training. GPU is faster for training.                                                        |\n",
    "| `in_memory`             | `False`               | Toggle if training data is loaded into memory. Not recommended due to high memory usage.                        |\n",
    "| **Output Parameters**   |                       |                                                                                                                 |\n",
    "| `save_path`             | `None`                | Where to save your trained model.                                                                               |\n",
    "\n",
    "### **CRITICAL** considerations\n",
    "\n",
    "#### Architecture\n",
    "The settings of the *Denoiser Architecture* cannot be changed without training a new model from scratch.\n",
    "\n",
    "#### Overtraining\n",
    "Overtraining is a significant concern when using the denoiser, as it employs a neural network internally. To mitigate this risk, the denoiser incorporates an automatic stopping mechanism that halts training if no further improvement is observed on the validation dataset. Nevertheless, caution must be exercised when selecting a high value for n_stacks or using a limited training dataset, as these factors can still increase the likelihood of overtraining. If overtraining does occur, it may result in high denoising quality for the training data but poor generalization for new data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b36036f614441",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63272c0ef73a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:48:12.774292413Z",
     "start_time": "2023-12-13T16:48:12.768683900Z"
    }
   },
   "outputs": [],
   "source": [
    "yaml_file = Path(\".\").absolute().parent.parent.joinpath(\"scripts/generate_pretrain_models.yaml\")\n",
    "\n",
    "with open(yaml_file, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "display(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f2424bc0df4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:48:12.806600500Z",
     "start_time": "2023-12-13T16:48:12.768958531Z"
    }
   },
   "outputs": [],
   "source": [
    "params = config[\"param\"]\n",
    "use_pytorch = config[\"use_pytorch\"]\n",
    "use_cpu = config[\"use_cpu\"]\n",
    "\n",
    "root = Path(config[\"root_path\"])\n",
    "model_path = Path(config[\"model_path\"])\n",
    "\n",
    "# change configurations if desired\n",
    "# use_pytorch = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597e910631f929a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Set up folders for training and saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c117c73b7eb3e96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:48:12.807472054Z",
     "start_time": "2023-12-13T16:48:12.792997370Z"
    }
   },
   "outputs": [],
   "source": [
    "# change to your data directory\n",
    "my_data_directory = Path(\"/media/janrei1/data/deep\")\n",
    "\n",
    "assert my_data_directory.exists(), f\"can't find data directory: {my_data_directory}\"\n",
    "\n",
    "root = my_data_directory.joinpath(root)\n",
    "if not root.is_dir():\n",
    "    root.mkdir(parents=True)\n",
    "print(f\"loading data from: {root}\")\n",
    "\n",
    "# Optional: download training files or provide your own\n",
    "# !astrocast download_datasets {{my_data_directory}}\n",
    "\n",
    "model_path = my_data_directory.joinpath(model_path)\n",
    "if not model_path.is_dir():\n",
    "    model_path.mkdir(parents=True)\n",
    "print(f\"saving models to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a619db6e6ed4b4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train models\n",
    "## Create all possible configuration combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f56a93eb078782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:48:12.808039837Z",
     "start_time": "2023-12-13T16:48:12.801179285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert single values to lists and keep lists/tuples as-is\n",
    "params = {k: [v] if not isinstance(v, (list, tuple)) else v for k, v in params.items()}\n",
    "\n",
    "# Generate all combinations\n",
    "keys, values = zip(*params.items())\n",
    "combinations = [dict(zip(keys, prod)) for prod in itertools.product(*values)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0093402622b54",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## iterate over combinations and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613437148d9f087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T21:11:58.707429219Z",
     "start_time": "2023-12-13T16:48:12.824714946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop over all combinations\n",
    "for param_set in combinations:\n",
    "    \n",
    "    name_parts = []\n",
    "    for key, value in param_set.items():\n",
    "        \n",
    "        if key in [\"epochs\", \"patience\", \"min_delta\"]:\n",
    "            continue\n",
    "        \n",
    "        if isinstance(value, (list, tuple)):\n",
    "            value_str = '_'.join(map(str, value))\n",
    "        else:\n",
    "            value_str = str(value)\n",
    "        \n",
    "        name_parts.append(f\"{key}_{value_str}\")\n",
    "    name = '-'.join(name_parts)\n",
    "    \n",
    "    for k, v in config[\"data\"].items():\n",
    "        \n",
    "        print(f\"{k}:{name}\")\n",
    "        \n",
    "        save_model_path = model_path.joinpath(f\"{k}_{name}\")\n",
    "        if save_model_path.joinpath(\"model.h5\").is_file():\n",
    "            print(f\"Skipping > model exists: {save_model_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            input_size = param_set[\"input_size\"]\n",
    "            pre_post_frames = param_set[\"pre_post_frames\"]\n",
    "            gap_frames = param_set[\"gap_frames\"]\n",
    "            train_rotation = param_set[\"train_rotation\"]\n",
    "            \n",
    "            n_stacks, kernel = param_set[\"architecture\"]\n",
    "            epochs = param_set[\"epochs\"]\n",
    "            patience = param_set[\"patience\"]\n",
    "            min_delta = param_set[\"min_delta\"]\n",
    "            \n",
    "            # Trainer\n",
    "            train_str = v[\"train\"]\n",
    "            if \"*\" in train_str:\n",
    "                train_paths = list(root.glob(train_str))\n",
    "            else:\n",
    "                train_paths = root.joinpath(train_str)\n",
    "            \n",
    "            # Validator\n",
    "            val_paths = None\n",
    "            if \"val\" in v:\n",
    "                val_str = v[\"train\"]\n",
    "                if \"*\" in val_str:\n",
    "                    val_paths = list(root.glob(val_str))\n",
    "                else:\n",
    "                    val_paths = root.joinpath(val_str)\n",
    "            \n",
    "            if not use_pytorch:\n",
    "                \n",
    "                train_gen = SubFrameGenerator(paths=train_paths, max_per_file=v[\"max_per_file\"], loc=v[\"loc\"],\n",
    "                                              input_size=input_size,\n",
    "                                              pre_post_frames=pre_post_frames, gap_frames=gap_frames,\n",
    "                                              allowed_rotation=train_rotation,\n",
    "                                              padding=None, batch_size=8, normalize=\"global\", in_memory=False,\n",
    "                                              allowed_flip=[0, 1], shuffle=True)\n",
    "                \n",
    "                # Validator\n",
    "                if val_paths is not None:\n",
    "                    \n",
    "                    val_gen = SubFrameGenerator(\n",
    "                            paths=val_paths, max_per_file=3, loc=v[\"loc\"], input_size=input_size,\n",
    "                            pre_post_frames=pre_post_frames, gap_frames=gap_frames, allowed_rotation=[0],\n",
    "                            padding=None, batch_size=16, normalize=\"global\", in_memory=False,\n",
    "                            cache_results=True,\n",
    "                            allowed_flip=[-1], shuffle=True)\n",
    "                \n",
    "                else:\n",
    "                    val_gen = None\n",
    "                \n",
    "                # Network\n",
    "                \n",
    "                net = Network(train_generator=train_gen, val_generator=val_gen, learning_rate=0.001, decay_rate=0.99,\n",
    "                              pretrained_weights=None,\n",
    "                              n_stacks=n_stacks, kernel=kernel,\n",
    "                              batchNormalize=False, use_cpu=use_cpu)\n",
    "                \n",
    "                net.run(batch_size=1, num_epochs=epochs, patience=patience, min_delta=min_delta,\n",
    "                        save_model=save_model_path)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                train_dataset = SubFrameDataset(paths=train_paths, input_size=input_size, loc=v[\"loc\"],\n",
    "                                                pre_post_frames=pre_post_frames, max_per_file=v[\"max_per_file\"],\n",
    "                                                gap_frames=gap_frames, allowed_rotation=train_rotation, padding=None,\n",
    "                                                normalize=\"global\", in_memory=False, allowed_flip=[0, 1], shuffle=True)\n",
    "                \n",
    "                val_dataset = None\n",
    "                if \"val\" in v:\n",
    "                    val_dataset = SubFrameDataset(paths=val_paths, input_size=input_size, loc=v[\"loc\"],\n",
    "                                                  pre_post_frames=pre_post_frames, max_per_file=3,\n",
    "                                                  gap_frames=gap_frames, allowed_rotation=0, padding=None,\n",
    "                                                  normalize=\"global\", in_memory=False, allowed_flip=-1, shuffle=True)\n",
    "                \n",
    "                net = PyTorchNetwork(train_dataset, val_dataset=val_dataset, batch_size=16, shuffle=True, num_workers=4,\n",
    "                                     learning_rate=0.001, momentum=0.9, decay_rate=0.1, decay_steps=30,\n",
    "                                     n_stacks=n_stacks, kernels=kernel, kernel_size=3, batch_normalize=False,\n",
    "                                     use_cpu=use_cpu)\n",
    "                \n",
    "                net.run(num_epochs=epochs, save_model=save_model_path, patience=patience, min_delta=min_delta)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            sys.exit(2)\n",
    "        \n",
    "        except Exception as err:\n",
    "            print(f\"Error in {k}:{name}: {err}\")\n",
    "            traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

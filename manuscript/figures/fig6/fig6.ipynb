{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T18:17:00.041262Z",
     "iopub.status.busy": "2024-03-13T18:17:00.041051Z",
     "iopub.status.idle": "2024-03-13T18:17:12.404651Z",
     "shell.execute_reply": "2024-03-13T18:17:12.404032Z",
     "shell.execute_reply.started": "2024-03-13T18:17:00.041240Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "import humanize\n",
    "import sys\n",
    "import os, psutil\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import logging\n",
    "\n",
    "import astrocast.reduction as red\n",
    "import astrocast.clustering as clust\n",
    "import astrocast.analysis as ana\n",
    "import astrocast.autoencoders as AE\n",
    "import astrocast.helper as helper\n",
    "import astrocast.experiments as exp\n",
    "\n",
    "for pack in [red, clust, helper, ana, AE, helper, exp]:\n",
    "    importlib.reload(pack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44fed0-ca1c-449a-a663-c93299565468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T18:17:12.406162Z",
     "iopub.status.busy": "2024-03-13T18:17:12.405475Z",
     "iopub.status.idle": "2024-03-13T18:17:20.635181Z",
     "shell.execute_reply": "2024-03-13T18:17:20.633110Z",
     "shell.execute_reply.started": "2024-03-13T18:17:12.406141Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(exp)\n",
    "\n",
    "z_range = (0, 10000)\n",
    "timings = (None, list(range(0, z_range[1], 1000)), None)\n",
    "dummy_parameters = []\n",
    "\n",
    "dummy = dict(\n",
    "        name=\"default\",\n",
    "        num_rows=1000,\n",
    "        # z0, z1 boundaries\n",
    "        z_range=z_range,\n",
    "        timings=timings,\n",
    "        timing_jitter=None,\n",
    "        timing_offset=5,\n",
    "        # Signal generators\n",
    "        )\n",
    "\n",
    "# Signal generators\n",
    "def_gen = dict(noise_amplitude=0.001, trace_length=(50, 50), parameter_fluctuations=0.01)\n",
    "\n",
    "# Identical\n",
    "dummy1 = dummy.copy()\n",
    "dummy1[\"name\"] = \"identical\"\n",
    "dummy1[\"generators\"] = (def_gen, def_gen)\n",
    "dummy_parameters.append(dummy1)\n",
    "\n",
    "# big diff\n",
    "dummy2 = dummy.copy()\n",
    "dummy2[\"name\"] = \"big_diff\"\n",
    "gen2 = def_gen.copy()\n",
    "gen2.update({\"b\": 2, \"plateau_duration\": 6})\n",
    "dummy2[\"generators\"] = (def_gen, gen2)\n",
    "dummy_parameters.append(dummy2)\n",
    "\n",
    "# small diff\n",
    "dummy3 = dummy.copy()\n",
    "dummy3[\"name\"] = \"small_diff\"\n",
    "gen1 = def_gen.copy()\n",
    "gen1.update({\"b\": 1.5, \"plateau_duration\": 2, \"signal_amplitude\": 1})\n",
    "gen2 = gen1.copy()\n",
    "gen2.update({\"b\": 1.9, \"signal_amplitude\": 1.02, \"leaky_k\": 0.15})\n",
    "dummy3[\"generators\"] = (gen1, gen2)\n",
    "dummy_parameters.append(dummy3)\n",
    "\n",
    "# tripple\n",
    "dummy4 = dummy.copy()\n",
    "dummy4[\"name\"] = \"tripplet\"\n",
    "gen1 = def_gen.copy()\n",
    "gen1.update({\"b\": 1, \"plateau_duration\": 1, \"signal_amplitude\": 1})\n",
    "gen2 = gen1.copy()\n",
    "gen2.update({\"b\": 0.8, \"plateau_duration\": 2})\n",
    "gen3 = gen1.copy()\n",
    "gen3.update({\"b\": 3, \"plateau_duration\": 5})\n",
    "dummy4[\"generators\"] = (gen1, gen2, gen3)\n",
    "dummy_parameters.append(dummy4)\n",
    "\n",
    "# variable length\n",
    "dummy5 = dummy.copy()\n",
    "dummy5[\"name\"] = \"variable_length\"\n",
    "gen1 = def_gen.copy()\n",
    "gen1.update({\"trace_length\": 60, \"ragged_allowed\": True, \"signal_amplitude\": None, \"abort_amplitude\": None})\n",
    "gen2 = gen1.copy()\n",
    "gen2.update({\"leaky_k\": 0.2})\n",
    "dummy5[\"generators\"] = (gen1, gen2)\n",
    "dummy_parameters.append(dummy5)\n",
    "\n",
    "# create experiments\n",
    "ex = exp.Experiments(dummy_parameters, replicates=3)\n",
    "\n",
    "ex.plot_traces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a50829-58d4-4f1a-8181-a4b926b948b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T18:17:20.639115Z",
     "iopub.status.busy": "2024-03-13T18:17:20.638802Z",
     "iopub.status.idle": "2024-03-13T18:26:03.622199Z",
     "shell.execute_reply": "2024-03-13T18:26:03.621648Z",
     "shell.execute_reply.started": "2024-03-13T18:17:20.639095Z"
    }
   },
   "outputs": [],
   "source": [
    "ex.create_embedding(dict(FExt=None, CNN=None, RNN=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c02342-a558-4081-ba9c-58108a61bd0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T18:26:03.623507Z",
     "iopub.status.busy": "2024-03-13T18:26:03.623283Z",
     "iopub.status.idle": "2024-03-13T18:33:12.349946Z",
     "shell.execute_reply": "2024-03-13T18:33:12.349289Z",
     "shell.execute_reply.started": "2024-03-13T18:26:03.623485Z"
    }
   },
   "outputs": [],
   "source": [
    "ex.conditional_contrasts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f49987-7778-4303-bc78-09eb79991c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T18:33:12.351139Z",
     "iopub.status.busy": "2024-03-13T18:33:12.350912Z",
     "iopub.status.idle": "2024-03-13T18:33:45.509074Z",
     "shell.execute_reply": "2024-03-13T18:33:45.508446Z",
     "shell.execute_reply.started": "2024-03-13T18:33:12.351119Z"
    }
   },
   "outputs": [],
   "source": [
    "ex.coincidence_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c6836-4f7c-4748-9d84-2aeb5e8f44d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T18:33:45.510191Z",
     "iopub.status.busy": "2024-03-13T18:33:45.509934Z",
     "iopub.status.idle": "2024-03-13T18:33:45.558045Z",
     "shell.execute_reply": "2024-03-13T18:33:45.557371Z",
     "shell.execute_reply.started": "2024-03-13T18:33:45.510167Z"
    }
   },
   "outputs": [],
   "source": [
    "results = ex.get_results()\n",
    "display(results.head(3))\n",
    "display(results.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4340c-5c88-4fee-b7fa-27ad00214d3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T19:20:47.112040Z",
     "iopub.status.busy": "2024-03-13T19:20:47.110195Z",
     "iopub.status.idle": "2024-03-13T19:20:53.330198Z",
     "shell.execute_reply": "2024-03-13T19:20:53.329492Z",
     "shell.execute_reply.started": "2024-03-13T19:20:47.111925Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(exp)\n",
    "\n",
    "panel_column = \"name\"\n",
    "panel_rows = [\"conditional_contrasts\", \"coincidence_detection\"]\n",
    "# chr(65)\n",
    "figsize = (3, 3)\n",
    "num_samples = 4\n",
    "alpha = .9\n",
    "linestyle = \"--\"\n",
    "\n",
    "# df = results[results.data_split == \"test\"]\n",
    "df = results.copy()\n",
    "\n",
    "if isinstance(panel_rows, str):\n",
    "    panel_rows = [panel_rows]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    panels = df[panel_column].unique()\n",
    "    N = 1 + len(panel_rows)\n",
    "    M = len(panels)\n",
    "    fig, axx = plt.subplots(N, M, figsize=(M * figsize[0], N * figsize[1]))\n",
    "    \n",
    "    # plot traces\n",
    "    img_y = 0\n",
    "    for img_x, name in enumerate(panels):\n",
    "        \n",
    "        ax = axx[img_y, img_x]\n",
    "        \n",
    "        plot = None\n",
    "        for eObj in ex.experiments:\n",
    "            if eObj.name == name:\n",
    "                plot = eObj.plot\n",
    "                break\n",
    "        \n",
    "        if plot is not None:\n",
    "            _ = plot.plot_traces(title=f\"{panel_column}: {name}\", num_samples=num_samples, by=\"group\", alpha=alpha,\n",
    "                                 linestyle=linestyle, ax=ax)\n",
    "    \n",
    "    # plot rows\n",
    "    for panel_row in panel_rows:\n",
    "        \n",
    "        img_y += 1\n",
    "        \n",
    "        for img_x, panel in enumerate(panels):\n",
    "            \n",
    "            ax = axx[img_y, img_x]\n",
    "            \n",
    "            selected = df[(df.evaluation_type == panel_row) & (df[panel_column] == panel)]\n",
    "            # _ = sns.barplot(data=selected, x=\"embedding\", y=\"score\", hue=\"type\", ax=ax)\n",
    "            # _ = sns.swarmplot(data=selected, x=\"embedding\", y=\"score\", hue=\"data_split\", style=\"cluster_type\", ax=ax)\n",
    "            \n",
    "            show_legend = True if ax == axx[img_y, -1] else False\n",
    "            \n",
    "            exp.Experiments.plot_heatmap(df=selected, evaluation_type=panel_row, index='embedding',\n",
    "                                         columns='data_split',\n",
    "                                         group_by=\"cluster_type\", show_legend=show_legend, ax=ax)\n",
    "    \n",
    "    # remove y-labels\n",
    "    axx_ = axx[1:, :].flatten().tolist()\n",
    "    for ax in axx_:\n",
    "        ax.set_ylabel(None)\n",
    "        ax.set_xlabel(None)\n",
    "    \n",
    "    for i, panel in enumerate(panel_rows):\n",
    "        axx[i + 1, 0].set_ylabel(panel.replace(\"_\", \" \"))\n",
    "    \n",
    "    # clean xticklabels\n",
    "    axx_ = axx[1:, :].flatten().tolist()\n",
    "    for ax in axx_:\n",
    "        yticklabels = ax.get_yticklabels()\n",
    "        yticklabels = [y.get_text().split(\"_\")[0] for y in yticklabels]\n",
    "        ax.set_yticklabels(yticklabels, rotation='vertical')\n",
    "    \n",
    "    # axx_ = axx[1:, 1:].flatten().tolist()\n",
    "    # for ax in axx_:\n",
    "    #     ax.set_yticklabels([])\n",
    "    \n",
    "    # legends\n",
    "    # axx_ = axx[1:, :-1].flatten().tolist()\n",
    "    # for ax in axx_:\n",
    "    #     ax.get_legend().remove()\n",
    "    \n",
    "    # axx_ = axx[:, -1].flatten().tolist()\n",
    "    # for ax in axx_:\n",
    "    #     sns.move_legend(ax, loc=\"upper left\", bbox_to_anchor=(1.04, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840dab4a-6be0-449e-b4fe-ef6346ce12fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T19:11:13.413382Z",
     "iopub.status.busy": "2024-03-13T19:11:13.413113Z",
     "iopub.status.idle": "2024-03-13T19:11:13.418202Z",
     "shell.execute_reply": "2024-03-13T19:11:13.417373Z",
     "shell.execute_reply.started": "2024-03-13T19:11:13.413359Z"
    }
   },
   "outputs": [],
   "source": [
    "t = yticklabels[0]\n",
    "t.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d51d8-f4f9-44f4-b547-62bec3f5550f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98397b-3f46-4516-9d27-740d79553b15",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.234172Z",
     "iopub.status.idle": "2024-03-13T18:33:50.234650Z",
     "shell.execute_reply": "2024-03-13T18:33:50.234507Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.234492Z"
    }
   },
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0759a9-8f0a-426d-a3f1-f20b97b4d57e",
   "metadata": {},
   "source": [
    "# Generate example datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c92b56-1199-4916-91a0-aec60603b922",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.235666Z",
     "iopub.status.idle": "2024-03-13T18:33:50.236012Z",
     "shell.execute_reply": "2024-03-13T18:33:50.235869Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.235855Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(helper)\n",
    "\n",
    "# default settings signal generator\n",
    "def_gen = dict(noise_amplitude=0.001, trace_length=(50, 50), parameter_fluctuations=0.01)\n",
    "ident = (def_gen, def_gen)\n",
    "\n",
    "# big diff\n",
    "def_diff = def_gen.copy()\n",
    "def_diff.update(dict(b=2, plateau_duration=6))\n",
    "diff = (def_gen, def_diff)\n",
    "\n",
    "# small diff\n",
    "small_diff_1 = def_gen.copy()\n",
    "small_diff_1.update(dict(b=1.5, plateau_duration=2, signal_amplitude=1))\n",
    "\n",
    "small_diff_2 = def_gen.copy()\n",
    "small_diff_2.update(dict(signal_amplitude=1))\n",
    "small_diff = (small_diff_1, small_diff_2)\n",
    "\n",
    "# tripple \n",
    "trip_1 = def_gen.copy()\n",
    "trip_1.update(dict(b=1, plateau_duration=1, signal_amplitude=1))\n",
    "\n",
    "trip_2 = def_gen.copy()\n",
    "trip_2.update(dict(b=0.8, plateau_duration=2, signal_amplitude=1))\n",
    "\n",
    "trip_3 = def_gen.copy()\n",
    "trip_3.update(dict(b=3, plateau_duration=5, signal_amplitude=1))\n",
    "triplet = [trip_1, trip_2, trip_3]\n",
    "\n",
    "# Variable Length\n",
    "def_var_1 = def_gen.copy()\n",
    "def_var_1.update(dict(trace_length=60, ragged_allowed=True, signal_amplitude=None, abort_amplitude=None))\n",
    "\n",
    "def_var_2 = def_var_1.copy()\n",
    "def_var_2.update(dict(leaky_k=0.2))\n",
    "var_length = (def_var_1, def_var_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df99f5-9a3d-41da-a6b4-167155a3ee36",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.236982Z",
     "iopub.status.idle": "2024-03-13T18:33:50.237340Z",
     "shell.execute_reply": "2024-03-13T18:33:50.237191Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.237174Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(ana)\n",
    "\n",
    "z_range = (0, 10000)\n",
    "timings = (None, list(range(0, z_range[1], 1000)), None)\n",
    "\n",
    "def_dummy = dict(num_rows=1000, z_range=z_range, timings=timings, timing_jitter=None, timing_offset=5)\n",
    "gen_params = {\"ident\": ident, \"diff\": diff, \"small_diff\": small_diff, \"triplet\": triplet, \"var_length\": var_length}\n",
    "\n",
    "experiments = {}\n",
    "e_id = 0\n",
    "for _ in range(1):\n",
    "    for k, gen_param in gen_params.items():\n",
    "        \n",
    "        experiments[e_id] = {}\n",
    "        \n",
    "        ############################################\n",
    "        # Create generator for identical populations\n",
    "        generators = [helper.SignalGenerator(**param, ) for param in gen_param]\n",
    "        dg = helper.DummyGenerator(generators=generators, **def_dummy)\n",
    "        \n",
    "        eObj = dg.get_events()\n",
    "        eObj.name = k\n",
    "        \n",
    "        # save events\n",
    "        experiments[e_id][\"eObj\"] = eObj\n",
    "        experiments[e_id][\"population_type\"] = eObj.name\n",
    "        \n",
    "        #########################\n",
    "        # Plot example population\n",
    "        param = dict(num_samples=4, by=\"group\", alpha=.9, linestyle=\"--\", )\n",
    "        \n",
    "        plot = ana.Plotting(eObj)\n",
    "        _ = plot.plot_traces(figsize=(4, 2), title=f\"Exp {e_id} ({k})\", **param)\n",
    "        \n",
    "        experiments[e_id][\"plot\"] = plot\n",
    "        \n",
    "        ##############\n",
    "        # increment id\n",
    "        e_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6adf5-8861-4863-be0e-69b706ec5e52",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cffdfb6-38ba-4a69-ae42-801445a480f6",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d7813-b402-441f-8e90-6ef6696f6851",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.238398Z",
     "iopub.status.idle": "2024-03-13T18:33:50.238784Z",
     "shell.execute_reply": "2024-03-13T18:33:50.238643Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.238628Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, exp in experiments.items():\n",
    "    eObj = exp[\"eObj\"]\n",
    "    \n",
    "    experiments[i][\"embeddings\"][\"FExt\"] = features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7dced-7411-4384-a497-74c7d67c6bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:18:35.152007Z",
     "iopub.status.busy": "2024-03-08T17:18:35.151662Z",
     "iopub.status.idle": "2024-03-08T17:18:35.155228Z",
     "shell.execute_reply": "2024-03-08T17:18:35.154630Z",
     "shell.execute_reply.started": "2024-03-08T17:18:35.151982Z"
    }
   },
   "source": [
    "### CNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c15aa60-bc4a-49e7-8984-88c3ebb21bdf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.239734Z",
     "iopub.status.idle": "2024-03-13T18:33:50.240086Z",
     "shell.execute_reply": "2024-03-13T18:33:50.239937Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.239919Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, exp in experiments.items():\n",
    "    eObj = exp[\"eObj\"]\n",
    "    \n",
    "    experiments[i][\"embeddings\"][\"CNN\"] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95b9b9-1e22-49c5-a7e3-b56e1238ee2b",
   "metadata": {},
   "source": [
    "### RNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f2403-cf7f-4204-ac15-57568b7dcb46",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.241160Z",
     "iopub.status.idle": "2024-03-13T18:33:50.241510Z",
     "shell.execute_reply": "2024-03-13T18:33:50.241371Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.241356Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, exp in experiments.items():\n",
    "    eObj = exp[\"eObj\"]\n",
    "    \n",
    "    experiments[i][\"embeddings\"][\"RNN\"] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e970a-4fe8-4e52-ba11-c4f12b4da5c1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Conditional Constrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b34b9f-bf44-43f1-8cf9-e5dc0f49b604",
   "metadata": {},
   "source": [
    "## Classifier (Predict condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a6f10-46d9-4e33-9cc6-ff16a4c06fe4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.242481Z",
     "iopub.status.idle": "2024-03-13T18:33:50.242827Z",
     "shell.execute_reply": "2024-03-13T18:33:50.242689Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.242673Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(clust)\n",
    "\n",
    "results = {k: [] for k in ['eid', 'dataset', 'embedding', 'data split', 'cm', 'accuracy', 'precision', 'recall', 'f1']}\n",
    "\n",
    "for i, exp in experiments.items():\n",
    "    eObj = exp[\"eObj\"]\n",
    "    \n",
    "    for emb_name, embedding in exp['embeddings'].items():\n",
    "        \n",
    "        discr = clust.Discriminator(eObj)\n",
    "        \n",
    "        clf = discr.train_classifier(embedding=embedding, category_vector=eObj.events.group.tolist())\n",
    "        res = discr.evaluate(show_plot=False, title=f\"condition: {eObj.name} [{emb_name}]\", figsize=(8, 4))\n",
    "        \n",
    "        for k, v in res.items():\n",
    "            \n",
    "            results['eid'].append(i)\n",
    "            results['dataset'].append(exp['population_type'])\n",
    "            results['embedding'].append(emb_name)\n",
    "            results['data split'].append(k)\n",
    "            results['cm'].append(v['cm'])\n",
    "            results['accuracy'].append(v['accuracy'])\n",
    "            results['precision'].append(v['precision'])\n",
    "            results['recall'].append(v['recall'])\n",
    "            results['f1'].append(v['f1'])\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b778f-afd4-4ade-a4a2-b3a0dc2e8b74",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.243736Z",
     "iopub.status.idle": "2024-03-13T18:33:50.244143Z",
     "shell.execute_reply": "2024-03-13T18:33:50.244016Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.244002Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_type = \"barplot\"\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    datasets = df.dataset.unique()\n",
    "    n_ds = len(datasets)\n",
    "    fig, axx = plt.subplots(2, n_ds, figsize=(int(3 * n_ds), 8))\n",
    "    \n",
    "    for n in range(n_ds):\n",
    "        \n",
    "        ds = datasets[n]\n",
    "        \n",
    "        # traces\n",
    "        plot = None\n",
    "        for i, exp in experiments.items():\n",
    "            if exp[\"population_type\"] == ds:\n",
    "                plot = exp['plot']\n",
    "                break\n",
    "        \n",
    "        if plot is not None:\n",
    "            _ = plot.plot_traces(num_samples=4, by=\"group\", ax=axx[0, n], alpha=.9, linestyle=\"--\")\n",
    "        \n",
    "        # precision\n",
    "        data = df[df.dataset == ds]\n",
    "        \n",
    "        if plot_type == \"pointplot\":\n",
    "            sns.pointplot(data=data, ax=axx[1, n], x=\"data split\", y=\"accuracy\", hue=\"embedding\", dodge=True)\n",
    "        \n",
    "        elif plot_type == \"barplot\":\n",
    "            sns.barplot(data=data, ax=axx[1, n], x=\"embedding\", y=\"accuracy\", hue=\"data split\")\n",
    "        \n",
    "        elif plot_type == \"violinplot\":\n",
    "            sns.violinplot(data=data, ax=axx[1, n], x=\"embedding\", y=\"accuracy\", hue=\"data split\", split=True)\n",
    "        else:\n",
    "            raise ValueError(f\"unknown plot type\")\n",
    "        \n",
    "        # axis label\n",
    "        axx[0, n].set_title(ds)\n",
    "    \n",
    "    # set random line\n",
    "    for ax in axx[1, :]:\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.axhline(0.5, linestyle=\"--\", color=\"gray\")\n",
    "    \n",
    "    # legends\n",
    "    for ax in axx[0, :-1]:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    for ax in axx[:, -1]:\n",
    "        sns.move_legend(ax, loc=\"upper left\", bbox_to_anchor=(1.04, 1))\n",
    "\n",
    "fig.savefig(\"conditional_classifier.png\", dpi=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704e801-c2b4-4d0c-9b8b-acd9b2a85771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:34:21.004131Z",
     "iopub.status.busy": "2024-03-11T17:34:21.003686Z",
     "iopub.status.idle": "2024-03-11T17:34:21.008562Z",
     "shell.execute_reply": "2024-03-11T17:34:21.007838Z",
     "shell.execute_reply.started": "2024-03-11T17:34:21.004107Z"
    }
   },
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a802001-24e0-4512-b8ab-3d3f5cecf23b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.245020Z",
     "iopub.status.idle": "2024-03-13T18:33:50.245305Z",
     "shell.execute_reply": "2024-03-13T18:33:50.245183Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.245169Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(clust)\n",
    "\n",
    "link = clust.Linkage()\n",
    "for i, exp in experiments.items():\n",
    "    eObj = exp[\"eObj\"]\n",
    "    \n",
    "    for correlation_type in ['pearson', 'dtw']:\n",
    "        \n",
    "        num_groups = len(eObj.events.group.unique())\n",
    "        \n",
    "        barycenters, cluster_lookup_table = link.get_barycenters(eObj.events,\n",
    "                                                                 cutoff=num_groups, criterion='maxclust',\n",
    "                                                                 distance_type=correlation_type\n",
    "                                                                 )\n",
    "        print(experiments[i][\"population_type\"], num_groups,\n",
    "              len(np.unique(list(cluster_lookup_table.values()))))\n",
    "        \n",
    "        if \"distance\" not in experiments[i]:\n",
    "            experiments[i][\"distance\"] = {}\n",
    "        \n",
    "        experiments[i][\"distance\"][correlation_type] = dict(barycenters=barycenters,\n",
    "                                                            cluster_lookup_table=cluster_lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3653a-aba4-4229-ac9e-00395810cb15",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.246237Z",
     "iopub.status.idle": "2024-03-13T18:33:50.246573Z",
     "shell.execute_reply": "2024-03-13T18:33:50.246447Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.246433Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(clust)\n",
    "\n",
    "results = {k: [] for k in\n",
    "           ['eid', 'dataset', 'distance', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'homogeneity_score',\n",
    "            'rand_score']}\n",
    "\n",
    "for i, exp in experiments.items():\n",
    "    eObj = exp[\"eObj\"]\n",
    "    \n",
    "    for corr_type, v in exp['distance'].items():\n",
    "        \n",
    "        true_labels = eObj.events.group.tolist()\n",
    "        predicted_labels = [v['cluster_lookup_table'][n] - 1 for n in range(len(true_labels))]\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            scores = clust.Discriminator.compute_scores(true_labels, predicted_labels, scoring=\"clustering\")\n",
    "            \n",
    "            cm = confusion_matrix(predicted_labels, true_labels, normalize=None)\n",
    "            experiments[i]['distance'][corr_type]['cm'] = cm\n",
    "            \n",
    "            results['eid'].append(i)\n",
    "            results['dataset'].append(exp['population_type'])\n",
    "            results['distance'].append(corr_type)\n",
    "            results['adjusted_mutual_info_score'].append(scores['adjusted_mutual_info_score'])\n",
    "            results['adjusted_rand_score'].append(scores['adjusted_rand_score'])\n",
    "            results['homogeneity_score'].append(scores['homogeneity_score'])\n",
    "            results['rand_score'].append(scores['rand_score'])\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b0023-8942-49e0-ad5c-d67d1518a6b0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.247506Z",
     "iopub.status.idle": "2024-03-13T18:33:50.247838Z",
     "shell.execute_reply": "2024-03-13T18:33:50.247706Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.247691Z"
    }
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    datasets = df.dataset.unique()\n",
    "    n_ds = len(datasets)\n",
    "    fig, axx = plt.subplots(2, n_ds, figsize=(int(3 * n_ds), 8))\n",
    "    \n",
    "    for n in range(n_ds):\n",
    "        \n",
    "        ds = datasets[n]\n",
    "        \n",
    "        # traces\n",
    "        plot = None\n",
    "        for i, exp in experiments.items():\n",
    "            if exp[\"population_type\"] == ds:\n",
    "                plot = exp['plot']\n",
    "                break\n",
    "        \n",
    "        if plot is not None:\n",
    "            _ = plot.plot_traces(num_samples=4, by=\"group\", ax=axx[0, n], alpha=.9, linestyle=\"--\")\n",
    "        \n",
    "        # precision\n",
    "        data = df[df.dataset == ds]\n",
    "        sns.barplot(data=data, ax=axx[1, n], x=\"distance\", y=\"rand_score\")\n",
    "        \n",
    "        # axis label\n",
    "        axx[0, n].set_title(ds)\n",
    "    \n",
    "    # set random line\n",
    "    for ax in axx[1, :]:\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.axhline(0.5, linestyle=\"--\", color=\"gray\")\n",
    "    \n",
    "    # legends\n",
    "    for ax in axx[0, :-1]:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    sns.move_legend(axx[0, -1], loc=\"upper left\", bbox_to_anchor=(1.04, 1))\n",
    "\n",
    "fig.savefig(\"conditional_hierarchical.png\", dpi=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2907e3-f451-4ff2-8233-50324ed542fc",
   "metadata": {},
   "source": [
    "# Coincidence detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecba070-dc46-4f09-9481-e2ebb062121b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.249238Z",
     "iopub.status.idle": "2024-03-13T18:33:50.249907Z",
     "shell.execute_reply": "2024-03-13T18:33:50.249725Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.249704Z"
    }
   },
   "outputs": [],
   "source": [
    "eObj = experiments[0][\"eObj\"]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    \n",
    "    Y = eObj.events.dz + np.random.normal(0, 5, size=len(eObj.events))\n",
    "    sns.scatterplot(data=eObj.events, x=\"z0\", y=Y, hue=\"group\",\n",
    "                    ax=ax)\n",
    "    \n",
    "    for v in timings[1]:\n",
    "        ax.axvline(v, color=\"gray\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87492cd-dc1a-44e7-81f7-0a027fa97664",
   "metadata": {},
   "source": [
    "## Classifer (Predict Incidence Occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32aab0-4491-4db1-9148-acd670c70503",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.251613Z",
     "iopub.status.idle": "2024-03-13T18:33:50.252147Z",
     "shell.execute_reply": "2024-03-13T18:33:50.251954Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.251933Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(clust)\n",
    "\n",
    "results = {k: [] for k in ['eid', 'dataset', 'embedding', 'data split', 'cm', 'accuracy', 'precision', 'recall', 'f1']}\n",
    "\n",
    "for i, exp in experiments.items():\n",
    "    eObj = exp[\"eObj\"]\n",
    "    \n",
    "    for emb_name, embedding in exp['embeddings'].items():\n",
    "        \n",
    "        cDetect = clust.CoincidenceDetection(events=eObj, incidences=timings[1], embedding=embedding)\n",
    "        \n",
    "        clf, res = cDetect.predict_coincidence(binary_classification=True)\n",
    "        \n",
    "        for k, v in res.items():\n",
    "            \n",
    "            results['eid'].append(i)\n",
    "            results['dataset'].append(exp['population_type'])\n",
    "            results['embedding'].append(emb_name)\n",
    "            results['data split'].append(k)\n",
    "            results['cm'].append(v['cm'])\n",
    "            results['accuracy'].append(v['accuracy'])\n",
    "            results['precision'].append(v['precision'])\n",
    "            results['recall'].append(v['recall'])\n",
    "            results['f1'].append(v['f1'])\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb8317-42c6-4e96-8c00-5200baf9d3fd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.253683Z",
     "iopub.status.idle": "2024-03-13T18:33:50.254368Z",
     "shell.execute_reply": "2024-03-13T18:33:50.254206Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.254188Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_type = \"barplot\"\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    datasets = df.dataset.unique()\n",
    "    n_ds = len(datasets)\n",
    "    fig, axx = plt.subplots(2, n_ds, figsize=(int(3 * n_ds), 8))\n",
    "    \n",
    "    for n in range(n_ds):\n",
    "        \n",
    "        ds = datasets[n]\n",
    "        \n",
    "        # traces\n",
    "        plot = None\n",
    "        for i, exp in experiments.items():\n",
    "            if exp[\"population_type\"] == ds:\n",
    "                plot = exp['plot']\n",
    "                break\n",
    "        \n",
    "        if plot is not None:\n",
    "            _ = plot.plot_traces(num_samples=4, by=\"group\", ax=axx[0, n], alpha=.9, linestyle=\"--\")\n",
    "        \n",
    "        # precision\n",
    "        data = df[df.dataset == ds]\n",
    "        \n",
    "        if plot_type == \"pointplot\":\n",
    "            sns.pointplot(data=data, ax=axx[1, n], x=\"data split\", y=\"accuracy\", hue=\"embedding\", dodge=True)\n",
    "        \n",
    "        elif plot_type == \"barplot\":\n",
    "            sns.barplot(data=data, ax=axx[1, n], x=\"embedding\", y=\"accuracy\", hue=\"data split\")\n",
    "        \n",
    "        elif plot_type == \"violinplot\":\n",
    "            sns.violinplot(data=data, ax=axx[1, n], x=\"embedding\", y=\"accuracy\", hue=\"data split\", split=True)\n",
    "        else:\n",
    "            raise ValueError(f\"unknown plot type\")\n",
    "        \n",
    "        # axis label\n",
    "        axx[0, n].set_title(ds)\n",
    "    \n",
    "    # set random line\n",
    "    for ax in axx[1, :]:\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.axhline(0.5, linestyle=\"--\", color=\"gray\")\n",
    "    \n",
    "    # legends\n",
    "    for ax in axx[0, :-1]:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    for ax in axx[:, -1]:\n",
    "        sns.move_legend(ax, loc=\"upper left\", bbox_to_anchor=(1.04, 1))\n",
    "\n",
    "# fig.savefig(\"conditional_classifier.png\", dpi=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac3a55-3ea4-4882-bb4f-d7152dec2726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8941ffdc-211c-462f-9baf-2ff738c7ecb1",
   "metadata": {},
   "source": [
    "## Regression (Predict timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51536ef-6896-482a-96f5-5a083605ea0a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.255604Z",
     "iopub.status.idle": "2024-03-13T18:33:50.256067Z",
     "shell.execute_reply": "2024-03-13T18:33:50.255893Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.255874Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(clust)\n",
    "\n",
    "results = {k: [] for k in ['eid', 'dataset', 'embedding', 'score']}\n",
    "\n",
    "for i, exp in experiments.items():\n",
    "    eObj = exp[\"eObj\"]\n",
    "    \n",
    "    for emb_name, embedding in exp['embeddings'].items():\n",
    "        \n",
    "        cDetect = clust.CoincidenceDetection(events=eObj, incidences=timings[1], embedding=embedding)\n",
    "        \n",
    "        clf, res = cDetect.predict_incidence_location()\n",
    "        \n",
    "        results['eid'].append(i)\n",
    "        results['dataset'].append(exp['population_type'])\n",
    "        results['embedding'].append(emb_name)\n",
    "        results['score'].append(res['score'])\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e18342-a88f-4893-8d85-815cd26f7a7c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-13T18:33:50.257926Z",
     "iopub.status.idle": "2024-03-13T18:33:50.258340Z",
     "shell.execute_reply": "2024-03-13T18:33:50.258175Z",
     "shell.execute_reply.started": "2024-03-13T18:33:50.258159Z"
    }
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    datasets = df.dataset.unique()\n",
    "    n_ds = len(datasets)\n",
    "    fig, axx = plt.subplots(2, n_ds, figsize=(int(3 * n_ds), 8))\n",
    "    \n",
    "    for n in range(n_ds):\n",
    "        \n",
    "        ds = datasets[n]\n",
    "        \n",
    "        # traces\n",
    "        plot = None\n",
    "        for i, exp in experiments.items():\n",
    "            if exp[\"population_type\"] == ds:\n",
    "                plot = exp['plot']\n",
    "                break\n",
    "        \n",
    "        if plot is not None:\n",
    "            _ = plot.plot_traces(num_samples=4, by=\"group\", ax=axx[0, n], alpha=.9, linestyle=\"--\")\n",
    "        \n",
    "        # precision\n",
    "        data = df[df.dataset == ds]\n",
    "        sns.barplot(data=data, ax=axx[1, n], x=\"embedding\", y=\"score\")\n",
    "        \n",
    "        # axis label\n",
    "        axx[0, n].set_title(ds)\n",
    "    \n",
    "    # set random line\n",
    "    for ax in axx[1, :]:\n",
    "        ax.set_ylim(-1.1, 1.1)\n",
    "    #     ax.axhline(0.5, linestyle=\"--\", color=\"gray\")\n",
    "    \n",
    "    # share y-axis\n",
    "    # for ax in axx[1, 1:]:\n",
    "    #     ax.sharey(axx[1, 0])\n",
    "    \n",
    "    # legends\n",
    "    for ax in axx[0, :-1]:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    # for ax in axx[:, -1]:\n",
    "    #     sns.move_legend(ax, loc=\"upper left\", bbox_to_anchor=(1.04, 1))\n",
    "\n",
    "# fig.savefig(\"conditional_classifier.png\", dpi=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383d6de-fc7f-474d-b766-d73f9a386486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
